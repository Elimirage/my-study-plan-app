import streamlit as st
import pandas as pd
import numpy as np
import json
from fgos import extract_text_from_pdf_file, extract_competencies_full, detect_profile_from_fgos
from profstandart import analyze_prof_standard, match_fgos_and_prof
from plan import generate_plan_pipeline
from utils import dataframe_to_excel_bytes




st.set_page_config(
    page_title="–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —É—á–µ–±–Ω–æ–≥–æ –ø–ª–∞–Ω–∞",
    layout="wide"
)

st.title("üìò –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —É—á–µ–±–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ –ø–æ –§–ì–û–° –∏ –ø—Ä–æ—Ñ—Å—Ç–∞–Ω–¥–∞—Ä—Ç—É")




tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "üìÑ –§–ì–û–°",
    "üìÑ –ü—Ä–æ—Ñ—Å—Ç–∞–Ω–¥–∞—Ä—Ç",
    "üîó –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ",
    "üìö –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–ª–∞–Ω–∞",
    "üì• –≠–∫—Å–ø–æ—Ä—Ç"
])




with tab1:

    st.header("üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –§–ì–û–°")

    uploaded_fgos = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –§–ì–û–° (PDF)", type=["pdf"])

    if uploaded_fgos:
        text_fgos = extract_text_from_pdf_file(uploaded_fgos)
        df_fgos = pd.DataFrame(extract_competencies_full(text_fgos))

        st.session_state.df_fgos = df_fgos
        st.session_state.fgos_text = text_fgos
        st.subheader("–ü–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞ –§–ì–û–°")
        st.text(text_fgos[:500])


        st.subheader("–ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏")
        st.dataframe(df_fgos, use_container_width=True)

        profiles = detect_profile_from_fgos(text_fgos)
        st.session_state.detected_profiles = profiles

        st.success(f"–û–ø—Ä–µ–¥–µ–ª—ë–Ω –ø—Ä–æ—Ñ–∏–ª—å: {', '.join(profiles)}")




with tab2:
    st.header("üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ—Ñ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞")

    uploaded_prof = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –ø—Ä–æ—Ñ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞ (PDF)", type=["pdf"])

    if uploaded_prof:
        text_prof = extract_text_from_pdf_file(uploaded_prof)
        tf_struct, error = analyze_prof_standard(text_prof)

        if error:
            st.error(error)
        else:
            st.session_state.tf_struct = tf_struct
            st.success(f"–ù–∞–π–¥–µ–Ω–æ {len(tf_struct['TF'])} —Ç—Ä—É–¥–æ–≤—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π")



with tab3:
    st.header("üîó –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –§–ì–û–° –∏ –ø—Ä–æ—Ñ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞")

    if "df_fgos" in st.session_state and "tf_struct" in st.session_state:
        match_json, error = match_fgos_and_prof(
            st.session_state.df_fgos,
            st.session_state.tf_struct
        )

        st.session_state.match_json = match_json

        st.success("–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ")
        st.json(match_json)
    else:
        st.warning("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –§–ì–û–° –∏ –ø—Ä–æ—Ñ—Å—Ç–∞–Ω–¥–∞—Ä—Ç")



with tab4:
    st.header("üìö –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É—á–µ–±–Ω–æ–≥–æ –ø–ª–∞–Ω–∞")

    ready = all(k in st.session_state for k in [
        "df_fgos", "tf_struct", "match_json", "fgos_text"
    ])

    if not ready:
        st.warning("–ù–µ —Ö–≤–∞—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–ª–∞–Ω–∞")
    else:
        # –ö–Ω–æ–ø–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        if st.button("üîÑ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —É—á–µ–±–Ω—ã–π –ø–ª–∞–Ω –∑–∞–Ω–æ–≤–æ"):
            df_plan = generate_plan_pipeline(
                st.session_state.df_fgos,
                st.session_state.tf_struct,
                st.session_state.match_json,
                st.session_state.fgos_text
            )
            st.session_state.df_plan = df_plan

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–ª–∞–Ω, –µ—Å–ª–∏ –æ–Ω —É–∂–µ –µ—Å—Ç—å
        if "df_plan" in st.session_state:
            st.success("–£—á–µ–±–Ω—ã–π –ø–ª–∞–Ω –≥–æ—Ç–æ–≤")
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ø–∏—Å–∫–∏ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π –≤ —Å—Ç—Ä–æ–∫–∏, —á—Ç–æ–±—ã PyArrow –Ω–µ –ø–∞–¥–∞–ª
            df = st.session_state.df_plan.copy()

            

            df = st.session_state.df_plan.copy()

            def normalize_cell(x):
                if isinstance(x, (list, tuple, set, np.ndarray)):
                    return ", ".join(map(str, x))
                if isinstance(x, dict):
                    return json.dumps(x, ensure_ascii=False)
                return x

            for col in df.columns:
                df[col] = df[col].apply(normalize_cell)

            st.dataframe(df, use_container_width=True)


            st.dataframe(df, use_container_width=True)



with tab5:
    st.header("üì• –≠–∫—Å–ø–æ—Ä—Ç —É—á–µ–±–Ω–æ–≥–æ –ø–ª–∞–Ω–∞")

    if "df_plan" in st.session_state:
        bytes_xlsx = dataframe_to_excel_bytes(st.session_state.df_plan)

        st.download_button(
            "üì• –°–∫–∞—á–∞—Ç—å —É—á–µ–±–Ω—ã–π –ø–ª–∞–Ω –≤ Excel",
            data=bytes_xlsx,
            file_name="—É—á–µ–±–Ω—ã–π_–ø–ª–∞–Ω.xlsx"
        )
    else:
        st.warning("–°–Ω–∞—á–∞–ª–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π—Ç–µ —É—á–µ–±–Ω—ã–π –ø–ª–∞–Ω")
